{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Primer-clasificador-binary.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkRuwwzRiQnm"
      },
      "source": [
        "# Base Notebook Delivery Apps Review Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRkv_kxaiVQd"
      },
      "source": [
        "# Imports, Global Variables and Downloads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdoQlTeIZjak"
      },
      "source": [
        "Transformers es la libreria que nos permite usar BERT\n",
        "\n",
        "\n",
        "nlpaug data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lj_69_t8k60p",
        "outputId": "0b4fea00-fedd-4ab5-aad6-2daf57a7bca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "source": [
        "!pip install transformers\n",
        "!pip install nlpaug"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.3.1)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: nlpaug in /usr/local/lib/python3.6/dist-packages (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHfJm3KXIWaK"
      },
      "source": [
        "import transformers\n",
        "import torch\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nlpaug.augmenter.word as naw\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "from torch import nn\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils import data\n",
        "\n",
        "BERT_HUGGINGFACE_PRE_TRAINED_MODEL_NAME = 'dccuchile/bert-base-spanish-wwm-cased'\n",
        "\n",
        "MAX_LEN = 70\n",
        "BATCH_SIZE = 64 # 8 16 32 64 128 256\n",
        "EPOCHS = 4\n",
        "RANDOM_SEED = 42\n",
        "TARGET_CLASS = 'Support'\n",
        "DOWNLOAD_MODEL = False"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtqWdQTk2zjx"
      },
      "source": [
        "Downloading dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne-1yhG2cTkm",
        "outputId": "096c0a88-d3ce-49cf-983c-0c5b949fd927",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "!gdown --id 16HheP0nKEJCxzsIE3jbWvt8Xz-pmtuuI --output review_dataset.csv"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16HheP0nKEJCxzsIE3jbWvt8Xz-pmtuuI\n",
            "To: /content/review_dataset.csv\n",
            "\r  0% 0.00/247k [00:00<?, ?B/s]\r100% 247k/247k [00:00<00:00, 39.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4uz1yIx21j1"
      },
      "source": [
        "Downloading fasttext spanish word embedding for data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wN69dgjLT7l",
        "outputId": "5fb50cf3-d3e1-443c-d34a-607c48b0836b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "!gdown --id 1ytY_Pr1XUy9v5abbOxBIHdcZ0GMJl1M2 --output fasttext-sbwc.vec"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ytY_Pr1XUy9v5abbOxBIHdcZ0GMJl1M2\n",
            "To: /content/fasttext-sbwc.vec\n",
            "2.24GB [00:25, 87.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YomSvWhB26hi"
      },
      "source": [
        "Si no aparece la nvidia hay que ir a Runtime > Change Runtime type > GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpC4gBMWoPk3",
        "outputId": "52dc1482-5a9e-4543-8c90-1d385b273efe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Oct 20 03:05:27 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P8    10W /  70W |     10MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1fh2QX6oS9g",
        "outputId": "8adb681c-ca60-4355-dcef-627b3ba75216",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVdwLHyDidbl"
      },
      "source": [
        "# Choose dataset and classification target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfPETVALKTqr",
        "outputId": "0a646343-c47a-4e27-ed40-704a74bdb67c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "def get_dataset_dataset(file, columns, index, convert2int64, naval=-1, preview=False):\n",
        "    \"\"\"Carga el csv de file\n",
        "    Completa las columnas con los valores requeridos\n",
        "    Pasa todos los valores numericos a int64.\n",
        "    Vuela el doble Index\n",
        "    Vuela todos los NaN: Poner el numero 'naval' para los valores null \"\"\"\n",
        "    df = pd.read_csv(file, names=columns)\n",
        "    df.set_index(index, inplace=True)\n",
        "\n",
        "    for col in convert2int64:\n",
        "        df[col] = df[col].fillna(naval)\n",
        "        df[col] = df[col].astype(np.float64)\n",
        "    \n",
        "    if preview:\n",
        "        print(df.head())\n",
        "        print('\\n', \"-------------------------\", '\\n')\n",
        "        print(df.info())\n",
        "    \n",
        "    return df\n",
        "\n",
        "df = get_dataset_dataset(\n",
        "    \"review_dataset.csv\",\n",
        "    [\"Index\", \"Content\", \"Sentiment\", \"App\", \"Service\", \"Support\"],\n",
        "    'Index',\n",
        "    convert2int64=['Sentiment', 'App', \"Service\", \"Support\"],\n",
        "    preview=True\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                  Content  Sentiment  App  Service  Support\n",
            "Index                                                                      \n",
            "2094                Agilidad y protocolos        2.0 -1.0      2.0     -1.0\n",
            "474                              Exelente        2.0  2.0     -1.0     -1.0\n",
            "874       Muy buena recepcion de producto        2.0 -1.0      2.0     -1.0\n",
            "189    Se queda en negro al querer entrar        0.0  0.0     -1.0     -1.0\n",
            "1976                          son lindos!        2.0 -1.0     -1.0     -1.0\n",
            "\n",
            " ------------------------- \n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 2150 entries, 2094 to 1352\n",
            "Data columns (total 5 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   Content    2150 non-null   object \n",
            " 1   Sentiment  2150 non-null   float64\n",
            " 2   App        2150 non-null   float64\n",
            " 3   Service    2150 non-null   float64\n",
            " 4   Support    2150 non-null   float64\n",
            "dtypes: float64(4), object(1)\n",
            "memory usage: 100.8+ KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrVhC5l7UCy3",
        "outputId": "f4a1af2b-f6a0-4752-a627-4b9cd1d01882",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "def get_dataset_for_classification(df, clase, binarize=True, binval=-1, preview=False):\n",
        "    \"\"\"Returns the dataframe with its content and a specific class for posteriori classification\n",
        "    If binarize is set to True, it returns the class binabinarized_service_df.head()\n",
        "    binarized_service_df.info()rized, mapping binval to 0 and other to 1\n",
        "    \"\"\"\n",
        "\n",
        "    new_df = df[['Content', clase]].copy()\n",
        "\n",
        "    if binarize:\n",
        "        new_df[clase] = new_df[clase].apply(lambda x: 0 if x == binval else 1)\n",
        "\n",
        "    if preview:\n",
        "        print(new_df.head())\n",
        "        print('\\n', \"-\" * 40, '\\n')\n",
        "        print(new_df.info())\n",
        "\n",
        "    return new_df\n",
        "\n",
        "binarized_class_df = get_dataset_for_classification(df, TARGET_CLASS, preview=True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                  Content  Support\n",
            "Index                                             \n",
            "2094                Agilidad y protocolos        0\n",
            "474                              Exelente        0\n",
            "874       Muy buena recepcion de producto        0\n",
            "189    Se queda en negro al querer entrar        0\n",
            "1976                          son lindos!        0\n",
            "\n",
            " ---------------------------------------- \n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 2150 entries, 2094 to 1352\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   Content  2150 non-null   object\n",
            " 1   Support  2150 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 50.4+ KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btA4EV_Mih0G"
      },
      "source": [
        "# Data analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmJY8PuKdTMI",
        "outputId": "2326f4df-4cbc-4fa2-9b5f-efc484e63c91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "source": [
        "ax = sns.countplot(binarized_class_df[TARGET_CLASS])\n",
        "plt.xlabel(f'{TARGET_CLASS}')\n",
        "ax.set_xticklabels(['No Pertenece', 'Pertenece']);"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxnRFGfgjzfq"
      },
      "source": [
        "# Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prNyIlBAjJiX"
      },
      "source": [
        "tokenizer = transformers.BertTokenizer.from_pretrained(BERT_HUGGINGFACE_PRE_TRAINED_MODEL_NAME)\n",
        "\n",
        "if DOWNLOAD_MODEL:\n",
        "    # Fijarme si n ohay un downlaod folder\n",
        "    tokenizer.save_pretrained('tokenizer_state')\n",
        "    files.download('tokenizer_state/special_tokens_map.json')\n",
        "    files.download('tokenizer_state/tokenizer_config.json')\n",
        "    files.download('tokenizer_state/vocab.txt')    "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NujcGX97lKKZ"
      },
      "source": [
        "# Creating Torch Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGG4YMpVk3fP"
      },
      "source": [
        "class GPReviewDataset(data.Dataset):\n",
        "    \"\"\"https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset\"\"\"\n",
        "\n",
        "    def __init__(self, review, target, tokenizer, max_len):\n",
        "        self.review = review # Contenido\n",
        "        self.target = target # Clase\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.review)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        review = str(self.review[item])\n",
        "\n",
        "        encoding = tokenizer.encode_plus(\n",
        "            review,\n",
        "            max_length=self.max_len,\n",
        "            add_special_tokens=True,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_token_type_ids=False,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'review_text': review,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'targets': torch.tensor(self.target[item], dtype=torch.long),\n",
        "        }"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrykONe8laQX"
      },
      "source": [
        "df_train, df_test = train_test_split(binarized_class_df, test_size=0.2, random_state=RANDOM_SEED)\n",
        "df_val, df_test = train_test_split(binarized_class_df, test_size=0.5, random_state=RANDOM_SEED)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_pV8auq0im0"
      },
      "source": [
        "# Data Augmentation: Word Embedding Agumenter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NggJWgaqCk1"
      },
      "source": [
        "Esto puede llevar como 6 minutos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdV5O_hKr2Ar"
      },
      "source": [
        "SKIP_STEP_DAWEA = False"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydruoGeK0iCK"
      },
      "source": [
        "def augment_df_with_nlpaug(df, content, target, aug_p=0.25, df_p=0.2, test_fun=False):\n",
        "    \"\"\"Augments the content of the dataset with similar words but retaining the target.\n",
        "    :df: Dataframe to agument\n",
        "    :content: column to agument\n",
        "    :target: column target\n",
        "    :bert_model: path to the pre trained bert model to use, default is set to hugging face transformer library\n",
        "    :aug_p: probability of changing a word\n",
        "    :df_p: probability to augment the row. 1 Augments all the dataset duplicating it.\n",
        "    returns a shuffled dataset with the new rows\n",
        "\n",
        "    https://github.com/makcedward/nlpaug/blob/master/example/textual_language_augmenter.ipynb\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    aug = naw.WordEmbsAug(model_type='fasttext',\n",
        "                    model_path=\"fasttext-sbwc.vec\", aug_min=2, aug_p=aug_p, aug_max=35)\n",
        "\n",
        "\n",
        "    for _, row in tqdm(df.iterrows()):\n",
        "        if test_fun:\n",
        "            print({\n",
        "                content: aug.augment(row[content]),\n",
        "                # Capaz a esto se le puede agregar algo que lo lleve al infinitivo\n",
        "                target: row[target]\n",
        "            })\n",
        "            break\n",
        "        if np.random.random() < df_p: \n",
        "            df = df.append({\n",
        "                content: aug.augment(row[content]),\n",
        "                target: row[target]\n",
        "            }, ignore_index=True)\n",
        "\n",
        "    return shuffle(df)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MoTb4QX4jJq",
        "outputId": "e5b31403-c37d-4f3f-94aa-8233c389b3bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if not SKIP_STEP_DAWEA:\n",
        "    df_train = augment_df_with_nlpaug(\n",
        "        df_train,\n",
        "        content='Content',\n",
        "        target=TARGET_CLASS,\n",
        "        test_fun=False # True, devuelve el primer comentario del df augmentado para poder observar\n",
        "        )"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1720it [05:49,  4.92it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PuLG7gKeDoQ"
      },
      "source": [
        "# Data Augmentation: Concatenate Comments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoHLuhdDidFl"
      },
      "source": [
        "La idea que puede servir para augmentar es concatenar comentarios de clases distintas para que el modelo entienda que cuando un comentario habla de muchas clases, tambien pertenece a la que uno esta analizando"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yq6a6gbak_1w"
      },
      "source": [
        "Si estamos teniendo en cuenta el sentimiento es MUY importante que no hagamos este step de pre procesamiento porque podria concatenar comentarios positivos y negativos de la misma clase y pifiarla heavy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I21cQOxyq2zf"
      },
      "source": [
        "SKIP_STEP_DACC = False"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA6jfacVizYa"
      },
      "source": [
        "def random_comment_concat(df, target, nanval=0, concat_prob=0.3, test_fun=False):\n",
        "    df = df.copy()\n",
        "    prev_comment = None\n",
        "    for _, row in tqdm(df.iterrows()):\n",
        "        if (np.random.random() < concat_prob and prev_comment is not None):\n",
        "            \n",
        "            if test_fun:\n",
        "                print(f'Actual comment: {row[\"Content\"]}')\n",
        "                print(f'Previous comment: {prev_comment}')\n",
        "            \n",
        "            new_comment = row['Content'] + ' ' + prev_comment\n",
        "            \n",
        "            if test_fun:\n",
        "                print(f'New comment: {new_comment}')\n",
        "                print()\n",
        "                print(f'Actual target: {row[target]}')\n",
        "                print(f'Previous target: {prev_target}')\n",
        "                print(f'New target: {row[target] or prev_target}')\n",
        "                break\n",
        "            \n",
        "            df = df.append({\n",
        "                'Content': new_comment,\n",
        "                target: row[target] or prev_target\n",
        "            }, ignore_index=True)\n",
        "\n",
        "        prev_comment = row['Content']\n",
        "        prev_target = row[target]\n",
        "\n",
        "    return shuffle(df)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIU_QV60l3j1",
        "outputId": "5f630776-d075-4673-95c5-8ee1c4e71b3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if not SKIP_STEP_DACC:\n",
        "    df_train = random_comment_concat(df_train, target=TARGET_CLASS, test_fun=False)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2094it [00:01, 1200.61it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIH-b2M9j9Hg"
      },
      "source": [
        "# Shapes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp3B9snwmCd-",
        "outputId": "7cee0dfc-80bb-4fd6-8e39-dcfc9b198afc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2734, 2), (1075, 2), (1075, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1Coz8Qkd9-v"
      },
      "source": [
        "# Create Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiDN4ZbxmNAw",
        "outputId": "278cfd12-c341-4679-f74c-fb12cdcbca9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "    ds = GPReviewDataset(\n",
        "        review=df['Content'].to_numpy(),\n",
        "        target=df[TARGET_CLASS].to_numpy(),\n",
        "        tokenizer=tokenizer,\n",
        "        max_len=max_len\n",
        "    )\n",
        "\n",
        "    return data.DataLoader(\n",
        "        ds,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=4\n",
        "    )\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "\n",
        "print(len(val_data_loader) * BATCH_SIZE)\n",
        "print(len(df_val[TARGET_CLASS]))\n",
        "\n",
        "data_batch = next(iter(train_data_loader)) # Returns a batch\n",
        "print(\"BATCH CHECK\")\n",
        "print(\"-\" * 40)\n",
        "print(\"Batch keys:\")\n",
        "print(data_batch.keys())\n",
        "print(\"-\" * 40)\n",
        "print(\"Batch input\")\n",
        "print(data_batch['input_ids'])\n",
        "print(\"-\" * 40)\n",
        "print(\"Batch Targets\")\n",
        "print(data_batch['targets'])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1088\n",
            "1075\n",
            "BATCH CHECK\n",
            "----------------------------------------\n",
            "Batch keys:\n",
            "dict_keys(['review_text', 'input_ids', 'attention_mask', 'targets'])\n",
            "----------------------------------------\n",
            "Batch input\n",
            "tensor([[    4,  5869,  2799,  ...,     1,     1,     1],\n",
            "        [    4,  1125,  1058,  ...,     1,     1,     1],\n",
            "        [    4,  1339, 18545,  ...,  1084,  1240,     5],\n",
            "        ...,\n",
            "        [    4, 22330,  1036,  ...,     1,     1,     1],\n",
            "        [    4,  1552, 11072,  ...,     1,     1,     1],\n",
            "        [    4,  3624,  1040,  ...,     1,     1,     1]])\n",
            "----------------------------------------\n",
            "Batch Targets\n",
            "tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "        0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zptl8YOXn50l"
      },
      "source": [
        "# Building Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuhsU6VJn2yi"
      },
      "source": [
        "class ReviewClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes):\n",
        "        super(ReviewClassifier, self).__init__()\n",
        "        self.bert = transformers.BertModel.from_pretrained(BERT_HUGGINGFACE_PRE_TRAINED_MODEL_NAME)\n",
        "        self.drop = nn.Dropout(p=0.3)\n",
        "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes) # = Dense en keras\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        _, pooled_output = self.bert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "        output = self.drop(pooled_output)\n",
        "\n",
        "        return self.sigmoid(self.out(output))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mftlA4GCoZKp",
        "outputId": "a2f8f95b-a497-410c-b2d1-cac8c2c04142",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "BINARY = 1\n",
        "model = ReviewClassifier(BINARY)\n",
        "model = model.to(device)\n",
        "print(model)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ReviewClassifier(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(31002, 768, padding_idx=1)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (drop): Dropout(p=0.3, inplace=False)\n",
            "  (out): Linear(in_features=768, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smOo3_ODo3Lg"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoQpM4Qdpa-8"
      },
      "source": [
        "optimizer = transformers.AdamW(model.parameters(), lr=2e-5, correct_bias=False) # based in BERT paper\n",
        "\n",
        "total_steps = len(train_data_loader) * EPOCHS # BATCH * EPOCHS\n",
        "\n",
        "scheduler = transformers.get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.BCELoss().to(device)\n",
        "loss_fn.requres_grad = True"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiJ1-L5qqHDK"
      },
      "source": [
        "def train_epoch(\n",
        "    model,\n",
        "    data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    n_examples\n",
        "):\n",
        "    model = model.train()\n",
        "\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    for d in tqdm(data_loader): # tqdm permite trackear visualmente el proceso\n",
        "        input_ids = d['input_ids'].to(device)\n",
        "        attention_mask = d['attention_mask'].to(device)\n",
        "        targets = d['targets'].to(device)\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "\n",
        "        outputs = outputs.flatten() # esto es la salida de la sigmoidea\n",
        "        loss = loss_fn(outputs, targets.float())\n",
        "\n",
        "        # PREDICTIONS \n",
        "        pred = torch.round(outputs) # redondeo crudo         \n",
        "        \n",
        "        correct_predictions += torch.sum(pred == targets)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) # If gradients are to large, the training is unstable, so gradient clipping fixes this\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHEuSa1jqOVP"
      },
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  with torch.no_grad():\n",
        "    for d in tqdm(data_loader):\n",
        "        input_ids = d[\"input_ids\"].to(device)\n",
        "        attention_mask = d[\"attention_mask\"].to(device)\n",
        "        targets = d[\"targets\"].to(device)\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "\n",
        "        outputs = outputs.flatten()\n",
        "        loss = loss_fn(outputs, targets.float())\n",
        "\n",
        "        # PREDICTIONS \n",
        "        pred = torch.round(outputs)        \n",
        "        \n",
        "        correct_predictions += torch.sum(pred == targets)\n",
        "\n",
        "        losses.append(loss.item())\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tY2iAvMsqRt3",
        "outputId": "e392b11a-2f4f-42e1-9843-8583bcbeb1e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    print()\n",
        "    print()\n",
        "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "    print('-' * 10)\n",
        "    print()\n",
        "\n",
        "    train_acc, train_loss = train_epoch(\n",
        "        model,\n",
        "        train_data_loader,\n",
        "        loss_fn,\n",
        "        optimizer,\n",
        "        device,\n",
        "        scheduler,\n",
        "        len(train_data_loader) * BATCH_SIZE\n",
        "    )\n",
        "\n",
        "    val_acc, val_loss = eval_model(\n",
        "        model,\n",
        "        val_data_loader,\n",
        "        loss_fn,\n",
        "        device,\n",
        "        len(val_data_loader) * BATCH_SIZE\n",
        "    )\n",
        "\n",
        "    print()\n",
        "    print(f'Train   loss {train_loss} accuracy {train_acc}')\n",
        "    print(f'Val     loss {val_loss} accuracy {val_acc}')\n",
        "    print()\n",
        "\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['train_loss'].append(train_loss)\n",
        "\n",
        "    if val_acc > best_accuracy:\n",
        "        torch.save(model.state_dict(), f'{TARGET_CLASS}_model.bin')\n",
        "        best_accuracy = val_acc"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/43 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Epoch 1/4\n",
            "----------\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 43/43 [00:30<00:00,  1.43it/s]\n",
            "100%|| 17/17 [00:04<00:00,  3.69it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train   loss 0.284825399777917 accuracy 0.8873546511627907\n",
            "Val     loss 0.11767029039123479 accuracy 0.9411764705882353\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/43 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Epoch 2/4\n",
            "----------\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 43/43 [00:30<00:00,  1.41it/s]\n",
            "100%|| 17/17 [00:04<00:00,  3.60it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train   loss 0.10927284127751062 accuracy 0.9553052325581395\n",
            "Val     loss 0.05982332895783817 accuracy 0.9650735294117647\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/43 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Epoch 3/4\n",
            "----------\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 43/43 [00:31<00:00,  1.38it/s]\n",
            "100%|| 17/17 [00:04<00:00,  3.58it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train   loss 0.031648536721720945 accuracy 0.9832848837209303\n",
            "Val     loss 0.009076046127387705 accuracy 0.9852941176470588\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/43 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Epoch 4/4\n",
            "----------\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 43/43 [00:31<00:00,  1.37it/s]\n",
            "100%|| 17/17 [00:04<00:00,  3.66it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train   loss 0.012160231294327004 accuracy 0.9905523255813954\n",
            "Val     loss 0.005913445185048177 accuracy 0.9862132352941176\n",
            "\n",
            "CPU times: user 1min 21s, sys: 1min, total: 2min 22s\n",
            "Wall time: 2min 28s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OStTk-FwwMHm"
      },
      "source": [
        "Download del modelo, aprox 450 MB tarda 14 min"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzsExYXTphKp"
      },
      "source": [
        "if DOWNLOAD_MODEL:\n",
        "    files.download(f'{TARGET_CLASS}_model.bin')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_Z0tmBK_SdT"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAhiZWl55wfI"
      },
      "source": [
        "def get_reviews(model, data_loader):\n",
        "    model = model.eval()\n",
        "\n",
        "    review_texts = []\n",
        "    predictions = []\n",
        "    prediction_probs = []\n",
        "    real_values = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for d in data_loader:\n",
        "\n",
        "            texts = d['review_text']\n",
        "            input_ids = d['input_ids'].to(device)\n",
        "            attention_mask = d['attention_mask'].to(device)\n",
        "            targets = d['targets'].to(device)\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask\n",
        "            )\n",
        "\n",
        "            preds = torch.round(outputs)\n",
        "            \n",
        "            review_texts.extend(texts)\n",
        "            predictions.extend(preds)\n",
        "            prediction_probs.extend(outputs)\n",
        "            real_values.extend(targets)\n",
        "\n",
        "    predictions = torch.stack(predictions).cpu()\n",
        "    prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "    real_values = torch.stack(real_values).cpu()\n",
        "\n",
        "    return review_texts, predictions, prediction_probs, real_values"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNw8q5-V_abg"
      },
      "source": [
        "model = ReviewClassifier(BINARY)\n",
        "model.load_state_dict(torch.load(f'{TARGET_CLASS}_model.bin'))\n",
        "model = model.to(device)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyI0iCs9_eh6",
        "outputId": "ea394c5b-5425-48dd-f1bb-416a6ef7544e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_acc, test_loss = eval_model(model, test_data_loader, loss_fn, device, len(df_test))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 17/17 [00:04<00:00,  3.52it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xREGEEMY_5Ja",
        "outputId": "fcc17342-8403-4431-c389-f875adb18621",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(test_acc)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.9693, device='cuda:0', dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2O7xqZ__kEZ"
      },
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_reviews(model, test_data_loader)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyCwZfeY_qlf",
        "outputId": "0eb73c4f-8996-4977-d8cf-e749788b197a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "print(classification_report(y_test, y_pred, target_names=[f'Not {TARGET_CLASS}', f'{TARGET_CLASS}']))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            " Not Support       0.99      0.98      0.98       996\n",
            "     Support       0.77      0.82      0.80        79\n",
            "\n",
            "    accuracy                           0.97      1075\n",
            "   macro avg       0.88      0.90      0.89      1075\n",
            "weighted avg       0.97      0.97      0.97      1075\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3nj9LCp_s8A"
      },
      "source": [
        "def show_confusion_matrix(confusion_matrix):\n",
        "    hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "    hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "    hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "    plt.ylabel('True sentiment')\n",
        "    plt.xlabel('Predicted sentiment')"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rccxYyIPAO_i",
        "outputId": "dc5cb156-0d63-4dfc-9c7d-942489b4db03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "df_cm = pd.DataFrame(cm, index=[f'Not {TARGET_CLASS}', f'{TARGET_CLASS}'], columns=[f'Not {TARGET_CLASS}', f'{TARGET_CLASS}'])\n",
        "show_confusion_matrix(df_cm)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-OzUGC7AldO"
      },
      "source": [
        "# Prueba Real"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vQIukNLAmwS",
        "outputId": "7d6b2b7f-8f87-4f21-ada8-b33cd5719d5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "review_text = \"\"\"Me intente comunicar para pedir ayuda un monton de veces y nunca me pudieron dar una solucion, pesimo!\n",
        "\"\"\"\n",
        "\n",
        "# review_text = \"Atencin al cliente es un curro nunca te resuelven nada\"\n",
        "\n",
        "encoded_review = tokenizer.encode_plus(\n",
        "    review_text,\n",
        "    max_length=MAX_LEN,\n",
        "    add_special_tokens=True,\n",
        "    return_token_type_ids=False,\n",
        "    padding='max_length',\n",
        "    return_attention_mask=True,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "input_ids = encoded_review['input_ids'].to(device)\n",
        "attention_mask = encoded_review['attention_mask'].to(device)\n",
        "\n",
        "output = model(input_ids, attention_mask)\n",
        "print(f'Prediction value: {output.tolist()[0][0]}')\n",
        "prediction = torch.round(output)\n",
        "\n",
        "clases = [f'Not {TARGET_CLASS}', f'{TARGET_CLASS}']\n",
        "\n",
        "print(f'Review text: {review_text}')\n",
        "print(f'Review text length: {len(tokenizer.tokenize(review_text))}')\n",
        "print(f'Category: {clases[int(prediction.tolist()[0][0])]}')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction value: 0.9958082437515259\n",
            "Review text: Me intente comunicar para pedir ayuda un monton de veces y nunca me pudieron dar una solucion, pesimo!\n",
            "\n",
            "Review text length: 22\n",
            "Category: Support\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_c279Z-DD5I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}